[{"content":" 本文使用环境： java sdk 1.8 + visual studio 2017\njava生成头文件 需声明待调用的dll中的方法为native方法\n1 2 3 4 5 6 7 8 // testDll.java public class testDll { static { System.loadLibrary(\u0026#34;testDll\u0026#34;); // dll名不需要加.dll的后缀 } public native List\u0026lt;List\u0026lt;float[]\u0026gt;\u0026gt; getValue(float[] nodeData, int nodeSize, String csvPath, String columnName) throws Exception; } 控制台使用javac（生成.class文件）和javah（生成.h文件）命令以生成.h文件。\n例如上述testDll.java在本级目录cmd命令为\n1 2 javac testDll.java javah testDll C++构建dll工程 Visual Studio新建DLL工程。注意，工程名必须与java约定的dll名一致。\n工程的附加包含目录需添加jni.h、jni_md.h所在的目录。\n将java生成的头文件加入工程，为其实现.cpp文件即可。\nJNI类型对应 Java 基本类型与 C++ 基本类型的对应关系是通过 JNI 提供的原生类型（如 jint, jfloat 等）来实现的。\nJava类型 C++类型 JNI对应类型 boolean bool jboolean byte char jbyte short short jshort int int jint long long jlong float float jfloat double double jdouble char char jchar Java 中的对象类型与 C++ 中的类或结构体对应。\nJava类型 JNI类型 string jstring object jobject class jclass ArrayList jobject int[] jintArray float[] jfloatArray double[] jdoubleArray long[] jlongArray object[] jobjectArray JNI常用函数 调用对象类方法 JNI调用对象类的函数使用逻辑大致为：获取到类(FindClass)→获取方法id(GetMethodId)→调用方法(Call***Method, ***取决于类型)【均通过JNIEnv * env操作】\nString 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // 获取 String 类 jclass stringClass = env-\u0026gt;FindClass(\u0026#34;java/lang/String\u0026#34;); if (stringClass == NULL) { env-\u0026gt;ExceptionDescribe(); return NULL; } // 获取 String 类的构造方法 String(String) jmethodID stringConstructor = env-\u0026gt;GetMethodID(stringClass, \u0026#34;\u0026lt;init\u0026gt;\u0026#34;, \u0026#34;(Ljava/lang/String;)V\u0026#34;); if (stringConstructor == NULL) { env-\u0026gt;ExceptionDescribe(); return NULL; } // 获取 String 类的实例方法 length() jmethodID lengthMethod = env-\u0026gt;GetMethodID(stringClass, \u0026#34;length\u0026#34;, \u0026#34;()I\u0026#34;); if (lengthMethod == NULL) { env-\u0026gt;ExceptionDescribe(); return NULL; } // 调用构造方法创建一个 String 对象 jstring inputString = env-\u0026gt;NewStringUTF(\u0026#34;Hello, JNI!\u0026#34;); jobject myString = env-\u0026gt;NewObject(stringClass, stringConstructor, inputString); // 调用 length() 方法获取字符串长度 jint length = env-\u0026gt;CallIntMethod(myString, lengthMethod); ArrayList 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // 获取 ArrayList 类 jclass arrayListClass = env-\u0026gt;FindClass(\u0026#34;java/util/ArrayList\u0026#34;); if (arrayListClass == NULL) { env-\u0026gt;ExceptionDescribe(); return NULL; } // 获取 ArrayList(int) 构造方法，用于指定初始容量 jmethodID arrayListConstructor = env-\u0026gt;GetMethodID(arrayListClass, \u0026#34;\u0026lt;init\u0026gt;\u0026#34;, \u0026#34;(I)V\u0026#34;); if (arrayListConstructor == NULL) { env-\u0026gt;ExceptionDescribe(); return NULL; } // 设定初始容量 int initialCapacity = 10; // 创建一个指定初始容量的 ArrayList jobject arrayListObj = env-\u0026gt;NewObject(arrayListClass, arrayListConstructor, initialCapacity); if (arrayListObj == NULL) { env-\u0026gt;ExceptionDescribe(); return NULL; } // 向 ArrayList 中添加元素 jmethodID addMethod = env-\u0026gt;GetMethodID(arrayListClass, \u0026#34;add\u0026#34;, \u0026#34;(Ljava/lang/Object;)Z\u0026#34;); if (addMethod == NULL) { env-\u0026gt;ExceptionDescribe(); return NULL; } // 创建字符串元素并添加到 ArrayList jstring element1 = env-\u0026gt;NewStringUTF(\u0026#34;Element 1\u0026#34;); env-\u0026gt;CallBooleanMethod(arrayListObj, addMethod, element1); env-\u0026gt;DeleteLocalRef(element1); jstring element2 = env-\u0026gt;NewStringUTF(\u0026#34;Element 2\u0026#34;); env-\u0026gt;CallBooleanMethod(arrayListObj, addMethod, element2); env-\u0026gt;DeleteLocalRef(element2); Exception 抛出异常\n1 2 3 4 5 6 7 8 9 10 jclass exceptionClass = env-\u0026gt;FindClass(\u0026#34;java/lang/RuntimeException\u0026#34;); if (exceptionClass == NULL) { return NULL; // 如果找不到异常类，直接返回 } // 创建异常消息 const char* msg = \u0026#34;An error occurred in JNI\u0026#34;; // 使用 ThrowNew 抛出异常 env-\u0026gt;ThrowNew(exceptionClass, msg); 捕获和处理 Java 层抛出的异常\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // 假设我们有一些 JNI 操作，可能会抛出异常 jmethodID methodID = env-\u0026gt;GetMethodID(someClass, \u0026#34;someMethod\u0026#34;, \u0026#34;()V\u0026#34;); if (methodID == NULL) { env-\u0026gt;ExceptionDescribe(); // 打印异常信息 env-\u0026gt;ExceptionClear(); // 清理异常状态 return NULL; } env-\u0026gt;CallVoidMethod(someObject, methodID); // 检查是否发生了异常 if (env-\u0026gt;ExceptionOccurred()) { env-\u0026gt;ExceptionDescribe(); // 打印异常信息 env-\u0026gt;ExceptionClear(); // 清理异常状态 return NULL; // 处理异常，返回 NULL } 普通数组 对于数组，通常不需要使用 GetFieldID 或 GetMethodID，因为数组操作通常通过 JNI 提供的专门函数来进行，例如 GetFloatArrayElements、SetFloatArrayRegion 等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 // 创建一个 float 数组 jfloatArray floatArray = env-\u0026gt;NewFloatArray(5); jfloat values[5] = { 1.1f, 2.2f, 3.3f, 4.4f, 5.5f }; // 将数据写入数组 env-\u0026gt;SetFloatArrayRegion(floatArray, 0, 5, values); // 获取数组中的元素 jfloat* arrayElements = env-\u0026gt;GetFloatArrayElements(floatArray, NULL); for (int i = 0; i \u0026lt; 5; i++) { printf(\u0026#34;Element at index %d: %f\\n\u0026#34;, i, arrayElements[i]); } env-\u0026gt;ReleaseFloatArrayElements(floatArray, arrayElements, 0); ","date":"2024-12-24T12:44:03+08:00","image":"/hiwikhome/jni-%E8%B0%83%E7%94%A8-dll/post_hu04bce9ff3cf39193bb266e9386cd2629_1184785_120x120_fill_box_smart1_3.png","permalink":"/hiwikhome/jni-%E8%B0%83%E7%94%A8-dll/","title":"JNI 调用 DLL"},{"content":"🌐 Part 1 数据系统的基石 🛡️CH 1 可靠性、可伸缩性和可维护性 服务级别目标（SLO, Service Level Objectives） 服务级别目标（SLO）是一种性能目标，它定义了服务提供者希望达到的服务水平。SLO通常包括服务的可用性、响应时间、吞吐量等关键性能指标（KPIs）。SLO是服务提供者内部的目标，它们可以用于监控服务性能，并作为改进服务的基准。SLO是服务级别协议（SLA）的基础，但它们不具有法律约束力，更多是作为内部标准来使用。\n服务级别协议（SLA, Service Level Agreements） 服务级别协议（SLA）是服务提供者和消费者之间的正式协议，它详细说明了服务提供者承诺提供的服务水平。SLA通常包括服务的可用性、响应时间、支持水平、问题解决时间等指标，并且这些指标都有明确的服务级别目标。SLA具有法律约束力，如果服务提供者未能达到SLA中规定的标准，可能会面临罚款或其他形式的处罚。\n头部阻塞（Head-of-Line Blocking, HOL Blocking） 头部阻塞是计算机网络和多线程系统中的一个术语，指的是在多队列系统中，一个队列的头部（即等待时间最长的元素）由于资源被其他队列占用而无法前进，导致整个系统的性能下降。例如，在数据库系统中，如果一个事务持有锁并且正在等待其他资源，它就会阻塞在其后面的所有事务，即使这些事务不依赖于被锁定的资源。这种现象会导致系统效率降低，因为它阻止了其他可以独立处理的事务的执行。\n排队延迟（queueing delay） 排队延迟通常占了高百分位点处响应时间的很大一部分。由于服务器只能并行处理少量的事务（如受其 CPU 核数的限制），所以只要有少量缓慢的请求就能阻碍后续请求的处理，这种效应有时被称为\u0026hellip;\n可靠性（Reliability） 可靠性意味着即使发生故障，系统也能正常工作。故障可能发生在硬件（通常是随机的和不相关的）、软件（通常是系统性的 Bug，很难处理）和人类（不可避免地时不时出错）。容错技术 可以对终端用户隐藏某些类型的故障。\n可伸缩性（Scalability） 可伸缩性意味着即使在负载增加的情况下也有保持性能的策略。为了讨论可伸缩性，我们首先需要定量描述负载和性能的方法。我们简要了解了推特主页时间线的例子，介绍描述负载的方法，并将响应时间百分位点作为衡量性能的一种方式。在可伸缩的系统中可以添加 处理容量 以在高负载下保持可靠。\n可维护性（Maintainability） 可维护性有许多方面，但实质上是关于工程师和运维团队的生活质量的。良好的抽象可以帮助降低复杂度，并使系统易于修改和适应新的应用场景。良好的可操作性意味着对系统的健康状态具有良好的可见性，并拥有有效的管理手段。\n🔑 CH 2 数据模型与查询语言 MySQL 执行 ALTER TABLE 时会复制整个表，可以通过优化 ALTER TABLE 命令的执行或使用特定的工具来减少这种影响。例如，使用如 pt-online-schema-change 等在线表结构变更工具，可以在不锁定整个表的情况下进行表结构的更改。 通常对于声明式查询语言来说，在编写查询语句时，不需要指定执行细节：查询优化程序会自动选择预测效率最高的策略，因此你可以专注于编写应用程序的其他部分。 💾 CH 3 存储与检索 SSTable：Sorted String Table（排序字符串表） 排序的键值对 SSTable 包含一系列排序的键值对，这种排序是持久化到磁盘之前就完成的。这个特性使得 SSTable 能够支持高效的范围查询和顺序读取操作。\n不可变性 一旦创建，SSTable 的内容不会改变。这使得 SSTable 非常适合并发读取，同时简化了数据的合并、缓存和恢复操作。\n索引 为了快速查找数据，SSTable 通常包含一个索引部分，记录了键到数据在文件中位置的映射。这个索引可以存储在文件的末尾，也可以部分或全部存储在内存中以提高查找速度。\n元数据 SSTable 可以包含额外的元数据，如最小和最大的键，这有助于在执行查询时快速确定是否需要查阅特定的 SSTable。\n压缩 为了节省存储空间，SSTable 文件通常会被压缩。常见的压缩算法包括 Snappy、Zlib 等。\n使用 SSTable 的存储引擎工作方式 新写入的数据首先添加至内存的平衡树数据结构，这个内存树有时被称为内存表（memtable）。 当内存表大于某个阈值时，将其作为 SSTable 写入硬盘，新的 SSTable 文件成为数据库的最新段，新的内容又可以写入一个最新的内存表实例。 收到请求后，优先在内存表寻找，接着再到最近的硬盘段，如果还没有再找下一个较旧的硬盘段，以此类推。 后台运行一个合并和压缩进程，以合并段文件并将已覆盖或删除的旧键删除。 LSM 树（Log-Structured Merge-tree） LSM 树是一种数据结构，用于高效管理在数据库和文件系统中的大量写操作。LSM 树通过将更新操作写入到内存中的结构，并且定期合并到磁盘上，优化了写入性能，特别是在需要处理大量写入操作的应用场景中。\n工作原理 内存中的写入：当进行数据插入、更新或删除操作时，LSM 树首先将这些变更写入到一个内存中的数据结构（通常是一个平衡树，如红黑树或AVL树），称为 MemTable。 日志写入：为了防止在系统崩溃时丢失数据，这些更改也会被写入到一个持久化的日志文件中。 磁盘合并：当 MemTable 达到一定大小后，它会被转换成一个不可变的磁盘文件，称为 SSTable（Sorted String Table）。这个过程被称为刷新（Flush）。 后台合并：随着时间的推移，这些 SSTable 会不断增加。LSM 树将定期在后台对这些 SSTable 进行合并和压缩（Compaction），以保持查询效率并回收空间。 优势与劣势 高效的写入性能：由于所有的写入首先进入内存，然后异步批量写入磁盘，因此可以获得非常高的写入性能。 写入放大问题的缓解：虽然 LSM 树在合并和压缩数据时会产生额外的磁盘写入，但通过优化这些操作可以有效管理写入放大问题。 适应大数据量的写入：LSM 树非常适合需要处理大量写入操作的应用，如日志数据处理和实时数据分析。 读取性能可能较低：由于数据分散在多个 SSTable 中，读取操作可能需要在多个文件中查找数据，导致读取性能不如 B-tree 等结构。 空间和写入放大：数据在合并过程中可能会被重写多次，导致磁盘使用效率较低和较高的写入放大。 Bloom Filters Bloom filter 是一种空间效率很高的概率性数据结构，用于测试一个元素是否属于一个集合。它允许有误报（false positives）的存在，即可能会错误地判断某个不存在的元素为存在于集合中，但绝不会有漏报（false negatives），即如果它说某个元素不存在，那么这个元素一定不存在于集合中。\n基本操作 添加元素：将元素通过多个哈希函数映射到一系列位置，并在这些位置上设置标记。 查询元素：对于给定的元素，再次使用相同的哈希函数计算位置，如果所有相关位置都被标记了，那么元素可能存在；如果有任何一个位置未被标记，则元素一定不存在。 Bloom filter 通常用在数据库和缓存系统中，以减少对磁盘的不必要访问，从而提高性能。\nSize-Tiered 和 Leveled Compaction 这两种术语来自于数据库系统中用于管理存储的压缩策略，特别是在使用 LSM 树结构的系统中。\nSize-Tiered Compaction (大小分层压缩) 这种压缩策略主要是将大小相似的 SSTables 合并成一个更大的 SSTable。当一组 SSTable 的总大小达到预设的阈值时，它们会被合并。 优点：适合写入量大、读取量小的场景，因为它可以减少合并频率，提高写入性能。 缺点：可能会产生较大的磁盘占用和延迟，因为合并操作本身较大且可能不够频繁。 Leveled Compaction (层级压缩) 在这种策略中，SSTables 被组织成多个层级。每个层级的大小是上一层的若干倍。新数据首先写入最低层，当这一层满了后，它会与下一层的 SSTables 进行合并。 优点：提供了更稳定的读性能和空间使用效率，因为每个键的数据版本在较少的文件中分散。 缺点：合并操作较频繁，可能会对写入性能产生影响。 B树 预写式日志（Write-Ahead Logging，简称 WAL） 为了使数据库能处理异常崩溃的场景，B 树实现通常会带有一个额外的硬盘数据结构：预写式日志（WAL，即 write-ahead log，也称为 重做日志，即 redo log）。\nWAL 的基本原理是，在任何数据更改写入到主数据文件之前，先将这些更改记录到一个单独的日志文件中。\n这是一个仅追加的文件，每个 B 树的修改在其能被应用到树本身的页面之前都必须先写入到该文件。当数据库在崩溃后恢复时，这\n个日志将被用来使 B 树恢复到一致的状态。\nB树 VS LSM 树 B树和LSM树（Log-Structured Merge-tree）是两种常用的数据结构，用于数据库和存储系统中管理和存储大量数据。虽然两者都被广泛应用，但它们的设计哲学、结构和适用场景有着明显的差异。\nB树的特点 结构：B树是一种自平衡的树，可以保持数据在多个层级中均匀分布。每个节点包含多个键和指向子节点的指针。B树通过分裂和合并节点来保持平衡。 读写性能：B树提供了较高的读写性能，尤其是在需要频繁读写且数据集较小（可以部分或完全放入内存）的情况下。 数据存取：在B树中，数据可以直接在任何节点中访问，这使得点查找非常快速。 适用场景：广泛用于传统的关系数据库中，如MySQL、PostgreSQL等，适合事务性应用。 LSM树的特点 结构：LSM树通过将所有写入操作首先记录在内存中的结构（如MemTable），然后异步批量写入磁盘，优化了写入性能。 写入优化：LSM树特别适合写密集型应用，因为它通过减少对磁盘的即时写入，延迟并批量处理这些操作来优化性能。 合并和压缩：LSM树定期在后台进行数据文件的合并和压缩，以保持高效的读取性能。 适用场景：常用于NoSQL数据库系统，如Cassandra和RocksDB等，适合大规模数据的分布式存储。 B树与LSM树的对比 读性能：B树由于其平衡的特性，提供了较快的读访问速度，特别是对于低延迟的点查找。LSM树可能在读取性能上不如B树，尤其是在存在大量SSTable时。 写性能：LSM树在写性能上通常优于B树，因为它通过批量写入和后台处理减少了磁盘I/O的需求。 空间和写入放大：LSM树在合并数据时可能会产生较大的写入放大和空间占用。B树通常对磁盘空间的利用更为高效。 维护复杂性：LSM树需要定期进行压缩和合并操作，这增加了系统的维护复杂性。B树的维护相对简单，因为它自动通过节点分裂和合并来保持平衡。 写入放大（write amplification）：在数据库的生命周期中每笔数据导致对硬盘的多次写入\n事务处理还是分析 表 3-1 比较事务处理和分析系统的特点\n属性 事务处理系统 OLTP 分析系统 OLAP 主要读取模式 查询少量记录，按键读取 在大批量记录上聚合 主要写入模式 随机访问，写入要求低延时 批量导入（ETL）或者事件流 主要用户 终端用户，通过 Web 应用 内部数据分析师，用于决策支持 处理的数据 数据的最新状态（当前时间点） 随时间推移的历史事件 数据集尺寸 GB ~ TB TB ~ PB 🔄 CH 4 编码与演化 向后与向前兼容性 向后兼容（Backward Compatibility）\n当前代码可以读取由旧版本代码写入的数据。\n向前兼容（Forward Compatibility）\n当前代码可以读取由新版本代码写入的数据。\n文本编码的缺点 数值类型支持不足\nCSV 和 XML：直接不支持数值类型，一切都是字符串。 JSON：虽然区分字符串和数值，但不细分数值类型。 二进制数据支持不足\n支持 Unicode 但对二进制数据支持不足，可能显示为乱码。 通常通过 Base64 编码来处理二进制数据，但这增加了处理复杂度。 额外的模式支持\nXML 和 JSON：支持通过模式来描述数据类型，虽然增强了功能，但也增加了复杂度。 CSV：没有任何模式支持。 数据模式的优点 省去字段名：数据更紧凑。 作为数据的注释或文档：模式总是与数据同步更新。 允许进行模式比对：可以不读取数据，仅通过模式进行兼容性检查。 静态类型支持：支持编译时类型检查，利于静态类型语言。 数据流模型 RPC（Remote Procedure Call） 远程过程调用，允许程序调用另一台计算机上的过程或函数，无需关心底层网络通信细节。\n消息队列 用于异步处理和分布式系统通信的技术，具有以下送达保证：\n最少一次：可能重复送达。 最多一次：可能丢失。 严格一次：确保恰好送达一次。 Actor 模型 一种并发计算模型，旨在简化并行计算和通信，具有以下特点：\n独立性：Actor之间不共享内存，通过消息传递交互。 并行性：支持并发执行，适用于分布式系统和多核环境。 隔离性和可扩展性：Actor故障互不影响，易于扩展系统。 🌍 Part 2 分布式数据 复制（Replication）\n在几个不同的节点上保存数据的相同副本，可能放在不同的位置。\n分区（Partitioning）\n将一个大型数据库拆分成较小的子集（称为分区（partitions）），从而不同的分区可以指派 给不同的节点（node）（亦称分片（shard））\n🔀 CH5 复制 关键：如何处理复制数据的变更\n主从复制模式 客户端要向数据库写入时，必须将请求发送给 leader ，leader 会将新数据写入其本地存储 leader 将新数据写入本地后，也会将数据变更发送给所有的 followers 复制日志（replication log）每个 followers 从leader 拉取日志后更新相应的本地数据库副本。 只有 leader 可写，followers 都是只读的 同步复制\u0026amp;异步复制 同步复制\n优点：从库保证有与主库一致的最新数据副本。如果主库突然失效，我们可以确信这些数据仍然能在从库上找到。 缺点：如果同步从库没有响应（比如它已经崩溃，或者出现网络故障，或其它任何原因），主库就无法处理写入操作。主库必须阻止所有写入，并等待同步副本再次可用。 半同步\n如果同步从库变得不可用或缓慢，则使一个异步从库同步。这保证你至少在两个节点上拥有最新的数据副本：主库和同步从库\n设置新从库步骤 获取某个时刻的主库的一致性快照 将快照复制到新的从库节点 从库连接到主库，并拉取快照之后的所有数据变更。 从库处理完数据变更后就 catch up 了主库 主库失效、故障切换 故障切换（Failover）：当主库失效时，一个从库被提升为新的主库，客户端和其他从库需要重新配置以指向新的主库。\n故障切换的过程\n确认主库失效：通常通过超时机制判断，如果节点在设定时间内无响应，则假定其失效。 选择新主库：可以通过选举过程或由控制器节点指定，最佳人选是拥有最新数据副本的从库。 系统重新配置：客户端的写请求需要指向新的主库，老主库需认可新领导并成为从库。 故障切换的挑战\n数据一致性问题：异步复制可能导致新主库缺少老主库宕机前的写入操作。 冲突处理：老主库重新加入集群时，可能与新主库存在写入冲突，常见解决方案是丢弃老主库未复制的写入。 外部存储协调：与外部存储系统协调时，丢弃写入可能导致数据不一致。 脑裂（Split Brain）：两个节点同时认为自己是主库，若无冲突解决机制，可能导致数据丢失或损坏。 屏蔽机制（Fencing）：采取措施防止脑裂，如关闭错误的主库节点。 故障切换的配置\n超时设置：超时时间需权衡，太长可能导致恢复延迟，太短可能导致不必要的故障切换。 手动与自动切换：尽管软件可能支持自动故障切换，但许多运维团队更倾向于手动执行以避免潜在问题。 日志复制 逻辑日志复制 通常是以行的粒度描述对数据库表的写入的记录序列 对于插入的行，日志包含所有列的新值 对于删除的行，日志包含足够的信息来唯一标识删除的行 对于更新的行，日志包含足够的信息来唯一标识更新的行及所有新列的值 复制延迟问题 read-your-writes consistency\n在一个异步复制的分布式数据库里，同一个客户端，写入主副本后返回；稍后再去读一个落后的从副本，发现读不到自己刚写的内容\n解决方式\n内容维度：读取的是用户自身的强相关的只有用户自己能读取到的内容时从主库读，其余的从从库读 时间维度：读取的内容的更新时间间隔较短则从主库读。可以根据主从复制延迟决定这个时间 moving backward in time\n查询一个延迟低的从库有数据，然后再去查询一个延迟高的从库却没数据。仿佛时光倒流，无事发生一样\n解决方式\n单调读取：确保每个用户都从同一份副本上读取 因果关系内容读取顺序颠倒\n内容的顺序是先A -\u0026gt; B, 但由于某些分区的复制速度慢于其他分区，得到的内容顺序却是 B-\u0026gt;A\n解决方式\n确保任何因果相关的写入都写入相同的分区 多主复制模式 写入的主库可以是多个，某个主库同时也是其他主库的 follow\n适用场景 多个数据中心，每个数据中心有自己的主库\n降低写入的延迟，提升性能体验 能够容忍某个数据中心停机 采用异步复制的多活配置能更好地承受网络问题 缺点 两个不同的数据中心可能同时修改数据，存在写入冲突 多主复制容易有配置缺陷，如自增主键，触发器，完整性约束 如何处理写入冲突 通过应用程序逻辑来避免冲突，例如确保相同的数据不会被多个节点同时修改。 最后写入胜出（Last Write Wins, LWW）：即最新的写入操作会覆盖旧的写入。 CRDTs（Conflict-free Replicated Data Types）：使用特殊的数据结构，它们天然支持复制并在没有中心协调者的情况下解决冲突。 版本向量（Vector Clocks）：使用向量时钟来跟踪每个副本的写入操作，解决冲突时可以根据向量时钟确定哪个写入是“最新”的。 无主复制模式 去中心化：没有单一的控制节点，所有节点都是平等的，可以独立地进行数据复制和同步。 数据一致性：虽然每个节点独立操作，但系统设计需要确保数据的最终一致性。这通常通过版本控制、向量时钟等机制来实现。 容错性：由于没有单一的故障点，系统对节点故障具有更好的容错性。即使某些节点不可用，其他节点仍然可以继续提供服务。 可扩展性：新节点可以轻松加入网络，而不需要重新配置主节点。这使得系统可以灵活地扩展。 冲突解决：在无主复制模式中，数据冲突是不可避免的。系统需要有一套机制来解决冲突，比如最后写入胜出（Last Write Wins, LWW）或者更复杂的冲突解决算法。 网络分区容忍性：无主复制模式通常与一些网络分区容忍性协议（如Raft或Paxos）结合使用，以确保即使在网络分区的情况下也能保持数据一致性。 读修复（Read Repair） 读修复是一种在读取数据过程中动态进行数据修复的策略。当客户端从分布式数据库或存储系统请求数据时，系统可能从多个副本中获取数据，以保证读取操作的高可用性和快速响应。读修复的工作流程通常如下：\n数据读取：客户端请求数据时，系统从多个数据副本中读取同一数据项。 版本比较：系统比较各副本的数据版本或时间戳。 检测不一致：如果发现副本之间存在版本差异，说明数据不一致。 修复数据：系统自动将最新版本的数据写回旧版本的副本中，更新这些副本。 读修复是一种懒惰修复策略，因为它仅在读取操作发生时才进行数据修复，可以降低网络和存储的压力，但可能导致过时数据在未被访问时长时间存在。\n反熵过程（Anti-entropy Process） 反熵过程是一种更加积极的数据一致性维护策略，用于系统地识别和修正数据副本间的不一致。它不依赖于用户的读取操作，而是周期性地在后台运行，扫描并同步数据副本。反熵过程主要有以下几种实现方式：\nMerkle树同步：使用Merkle树（一种哈希树）来比较数据副本的完整性和一致性。Merkle树可以有效地定位到不一致的数据块，从而减少数据同步过程中需要传输的数据量。 版本向量：通过维护一个包含所有副本版本信息的向量，系统可以识别并同步那些过时的副本。 全量或增量同步：定期进行全副本之间的数据比对和同步，或者仅同步自上次同步以来发生变化的数据部分。 反熵过程更加适合于那些对数据一致性要求较高的场景，能够确保即使在没有读取操作的情况下，数据副本也能保持一致。\n读写的法定人数（Quorum） 在分布式计算中，是一种确保数据一致性和可用性的常见策略。法定人数是基于多数投票的概念，用于决定在读取和写入操作中必须参与的节点的最小数量。这种策略是处理复制数据时一致性和可用性之间权衡的一种方法。\n基本概念\n法定人数的计算通常基于以下公式：\n写法定人数 (W)：必须成功写入的最小副本数。 读法定人数 (R)：必须成功读取的最小副本数。 N：总的副本数。 为了保证在任何时候都能读取到最新写入的数据，法定人数需要满足以下关系：\nR+W\u0026gt;N\n这个关系确保了至少有一个节点在读和写操作中同时被访问，从而能获取到最新的数据。\n法定人数策略的选择\n强一致性\n：\n如果系统要求非常强的数据一致性，可以选择较高的读写法定人数，例如 W=N和 R=1或 W=N和 R=N。这确保所有副本在每次写入后都是最新的，且每次读取都能返回最新数据。 高可用性\n：\n如果系统更重视可用性，可能选择 W=1 和 R=N，这样任何单一节点的写入都足以完成操作，而所有节点都参与到读操作中来确保返回最新数据。 平衡一致性和可用性\n：\n在许多实际应用中，会选择 W\u0026gt;N/2 和 R\u0026gt;N/2，这样任何写操作都至少会影响多数节点，任何读操作也至少访问多数节点，从而提供良好的一致性保证和合理的可用性。 CH 6 分区 CH 7 事务 ","date":"2024-10-08T22:42:52+08:00","image":"/hiwikhome/ddia/post_huec9c8375a74dfd66e0667829ad05739d_1025906_120x120_fill_box_smart1_3.png","permalink":"/hiwikhome/ddia/","title":"DDIA"},{"content":"为什么需要 IPv6 + DDNS IPV4 公网地址现在难以从运营商获取，即使可以获取也需要额外的价钱。IPV6 公网地址容易获取。 DDNS 服务会自动更新你的域名解析，以便即使你的 IPv6 地址发生变化，你依然可以通过同一个域名访问你的设备。 通过域名访问 NAS 比官方的 QC 速度更快。 前置准备 设备\n光猫，路由器支持 IPV6 DNS\n腾讯云、阿里云等运营商处购买一个域名 设备设置 光猫设置 电信网关举例\n进入网关后台 ：http://192.168.1.1 网络设置连接方式修改为 桥接，IP模式设置为 IPV4\u0026amp;IPV6 确认已开启 IPV6 路由器设置 小米路由器举例，后台地址http://192.168.2.1\n开启 IPV6 修改为 PPPOE 模式，输入账号，密码 设置端口转发，将群晖后台的端口进行转发设置，由于我是用的默认的 所以是 5000，5001。如有更改请自行配置。 设置校验 设置完毕后，群晖网络设置中能查看到分配到的 IPV6 公网 IP 地址， 如下图的 240e 开头这个\n群晖 NAS 设置 安装套件 DDNS-GO 去运营商处设置域名解析 设置主机记录，记录类型： AAAA ， 记录值为群晖的 IPV6地址\n进入DDNS-GO 进行设置 腾讯云需选择 DnsPod Token ， 同时在腾讯云的 DnsPod 创建一组 key，用于后续自动动态更新 IPV6 地址\n设置 DNS 服务商相关信息，ID 与 Token 填写刚创建的那组\nIPV6 处设置域名\nDDNS-GO 保存退出即可,完成后会弹出成功映射的提示弹窗，类似下图，至此已经完成了 IPVR 与 DDNS 相关配置的设置\nTips 路由器要设置为 PPPOE 模式, 光猫设置为桥接\n否则有可能出现 IPV6 公网地址获取不到的现象\n避免双重NAT问题\n光猫通常具有路由功能，默认情况下它会对连接的设备进行NAT（网络地址转换）。如果在光猫后再连接一个路由器并启用其路由功能，就会形成双重NAT（Double NAT）。双重NAT会导致网络性能下降，影响一些应用程序和服务的正常运行，尤其是需要端对端连接的应用，如在线游戏和VPN。 IPv6地址分配的优化\n在桥接模式下，光猫会将来自ISP（互联网服务提供商）的IP地址直接分配给下游设备（路由器）。这样，路由器可以直接从ISP获取一个公共的IPv6地址或前缀，从而更好地进行IPv6地址分配和管理。\n使用PPPoE拨号方式，路由器可以直接与ISP建立连接，获取完整的IPv6地址范围（通常是一个/64或更大范围的前缀），使内部网络中的每个设备都能获得一个公共的IPv6地址。\n不要用群晖官方自带的 DDNS 映射，官方的只支持 IPV4 的映射，所以此处选择套件 DDNS-GO\nPPPOE 模式的账号密码与光猫、路由器的后台密码，均可以找宽带小哥获取\n","date":"2024-06-02T18:18:02+08:00","image":"/hiwikhome/nasddns/post_huec4713c6e657007836b235ccc67872e3_5606494_120x120_fill_box_smart1_3.png","permalink":"/hiwikhome/nasddns/","title":"群晖IPV6 + DDNS"},{"content":"🐣 Maven 是什么 Maven是一个项目管理和自动化构建工具，它基于项目对象模型（POM，Project Object Model）的概念。Maven可以帮助开发者更好地构建和管理任何基于Java的项目。它使用一个中央信息库来存储项目的构建信息、依赖关系等。\n🐤 Maven 的核心概念 POM（Project Object Model）: POM是Maven项目的基本工作单元。它包含了项目的基本信息，比如项目名称、版本、依赖项、插件等。 依赖管理: Maven允许你指定项目依赖的外部库，自动从中央仓库下载这些依赖。 约定优于配置: Maven使用一个标准的目录布局和默认的构建生命周期，这意味着如果你遵循这些约定，你可以用最少的配置完成项目构建。 生命周期和插件: Maven的构建过程分为几个阶段（如编译、测试、打包等），每个阶段都可以绑定具体的任务，这些任务是通过插件来实现的。 🐥 Maven 标签 基础项目信息 \u0026lt;modelVersion\u0026gt;: 定义了POM模型的版本（通常是4.0.0）。\n1 \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;: 定义了项目的组ID，通常表示项目所属的组织或者公司。\n1 \u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;: 定义了项目的ID，这是项目的名称。\n1 \u0026lt;artifactId\u0026gt;my-application\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;: 定义了项目的版本。\n1 \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;packaging\u0026gt;: 定义了项目的打包方式，如jar、war等。\n1 \u0026lt;packaging\u0026gt;jar\u0026lt;/packaging\u0026gt; 依赖关系 \u0026lt;dependencies\u0026gt;: 包含项目所需的所有依赖。\n1 2 3 4 5 6 7 8 \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.12\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 构建配置 \u0026lt;build\u0026gt;: 包含构建的配置信息，如源代码目录、目标目录、插件等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.8.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;source\u0026gt;1.8\u0026lt;/source\u0026gt; \u0026lt;target\u0026gt;1.8\u0026lt;/target\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 插件 \u0026lt;plugins\u0026gt;: 定义了项目构建过程中使用的插件。\n1 2 3 4 5 6 7 \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.22.2\u0026lt;/version\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; 项目属性 \u0026lt;properties\u0026gt;: 定义了一些项目的属性，可以在POM中重用。\n1 2 3 \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; 分发管理 \u0026lt;distributionManagement\u0026gt;: 定义了项目分发的配置，如部署到Maven仓库的信息。\n1 2 3 4 5 6 7 \u0026lt;distributionManagement\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;central\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;Central Repository\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://path/to/your/repo\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/distributionManagement\u0026gt; 仓库 \u0026lt;repositories\u0026gt;: 定义项目所使用的其他仓库的位置。\n1 2 3 4 5 6 \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;central\u0026lt;/id\u0026gt; \u0026lt;url\u0026gt;https://repo.maven.apache.org/maven2\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; 配置文件管理 \u0026lt;profiles\u0026gt;: 定义了一组不同的配置，可以根据不同的环境选择性地激活。\n1 2 3 4 5 6 7 8 \u0026lt;profiles\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;development\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;environment\u0026gt;development\u0026lt;/environment\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt; 这些标签构成了Maven pom.xml文件的基本框架，允许你配置项目的构建、依赖、插件等方面的细节。通过组合这些标签，你可以灵活地管理和构建你的Java项目。\n🐦 Maven 的生命周期 Maven 使用一种称为构建生命周期的概念来管理项目构建过程。每个生命周期由一系列阶段（phase）组成，这些阶段在执行时按照特定的顺序进行。Maven 主要有三个标准的构建生命周期：clean、default（或称为build）和site。这些生命周期覆盖了项目的清理、构建和文档生成等方面。\n1 Clean 生命周期\nClean 生命周期的目的是清理项目，删除之前构建生成的所有文件。它主要包含以下三个阶段：\npre-clean：执行清理前的工作。 clean：清理上一次构建生成的所有文件。 post-clean：执行清理后的工作，如完成清理后的一些资源释放等。 2 Default 生命周期\nDefault 生命周期是Maven最核心的部分，负责项目的构建和部署。它包含了多个阶段，主要阶段如下：\nvalidate：验证项目是否正确，所有必要信息是否可用。 compile：编译项目的源代码。 test：使用适当的单元测试框架运行测试，这些测试不需要打包或部署。 package：打包编译后的代码，通常是创建JAR或WAR文件。 verify：对集成测试的结果进行检查，以确保质量达标。 install：将包安装到Maven本地仓库，供本地其他项目使用。 deploy：在构建环境中完成的最后一个阶段，将最终的包复制到远程仓库供其他开发人员和Maven项目使用。 3 Site 生命周期\nSite 生命周期负责创建和发布项目的站点文档。它包括以下阶段：\npre-site：执行生成项目站点前的工作。 site：生成项目的站点文档。 post-site：执行生成站点后的工作，如部署站点到服务器。 site-deploy：将生成的站点文档部署到特定的服务器上。 🐔 dependencies 和 dependencyManagement 在Maven项目中，\u0026lt;dependencies\u0026gt;和\u0026lt;dependencyManagement\u0026gt;是用来管理项目依赖的两个重要元素。它们的作用和使用场景有所不同\n\u0026lt;dependencies\u0026gt;\n\u0026lt;dependencies\u0026gt;元素用于明确声明项目直接依赖的外部库。当你在项目中需要使用某个库时，就在\u0026lt;dependencies\u0026gt;中添加一个\u0026lt;dependency\u0026gt;项。每个\u0026lt;dependency\u0026gt;项都会指定依赖的groupId、artifactId、version等信息。\n\u0026lt;dependencyManagement\u0026gt;\n\u0026lt;dependencyManagement\u0026gt;元素用于在父POM中统一管理项目的依赖版本，而不是直接引入依赖。在\u0026lt;dependencyManagement\u0026gt;内部声明的依赖不会直接加入到项目中，只有当子模块中声明了相同的groupId和artifactId时，\u0026lt;dependencyManagement\u0026gt;中指定的版本和范围（scope）等才会生效。这使得在多模块项目中能够很方便地统一管理依赖版本，避免了版本冲突和依赖的重复声明。\n在父POM中使用\u0026lt;dependencyManagement\u0026gt;管理多模块项目的依赖版本：子模块需要这个依赖时，应该在子模块的pom.xml中的\u0026lt;dependencies\u0026gt;部分声明这个依赖，这样才能真正引入到子模块中。 在单个模块项目中或父模块自身需要使用某个依赖：除了在\u0026lt;dependencyManagement\u0026gt;中指定版本信息外，还需要在\u0026lt;dependencies\u0026gt;中声明这个依赖，才能将其引入项目中。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.3.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;!-- 这里不需要指定版本，因为已经在\u0026lt;dependencyManagement\u0026gt;中指定 --\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 🪶 附录 Maven 官方文档\n","date":"2024-04-02T21:23:46+08:00","image":"/hiwikhome/mavenstudy/post_hueb621f978de5fae18ec16176d1b7cab7_654120_120x120_fill_box_smart1_3.png","permalink":"/hiwikhome/mavenstudy/","title":"Maven入门与介绍"},{"content":"1. 函数式数据处理 行为参数化 行为参数化是一种编程范式，它允许方法的行为通过参数的形式传递和修改。这种技术在处理变化的需求时非常有用，因为它使得代码更加灵活，能够适应不同的行为而无需修改方法本身。行为参数化是函数式编程思想在面向对象编程语言中的一种体现，特别是在Java 8中，通过使用Lambda表达式和方法引用，行为参数化变得更加简单和直观。\nLambda parameters -\u0026gt; expression 或 (parameters)-\u0026gt;{statement;}\n当 Lambda 表达式被用在一个期望 void 返回类型的上下文时,表达式的返回值会被忽略,而表达式本身会被当做一个语句来执行. 如果 Lambda 允许捕获可改变的局部变量,就会引发线程不安全的新可能性. 函数式接口 定义\n只定义一个抽象方法的接口 使用 @FunctionalInterface 注解函数式接口 只有在接受函数式接口的地方才可以使用 lambda 表达式 例子\nPredicate Predicate 通常用于过滤数据或匹配数据 1 2 3 4 @FunctionalInterface public interface Predicate\u0026lt;T\u0026gt; { boolean test(T t); } Consumer 适用于需要访问对象的操作中，比如从集合中的每个元素中提取信息或者对每个元素应用某个操作。 1 2 3 4 @FunctionalInterface public interface consumer\u0026lt;T\u0026gt; { void accept(T t); } Function Function 接口非常适用于转换数据、从一种类型映射到另一种类型的场景。 这里，@FunctionalInterface 注解表明这是一个函数式接口，而接口中的 apply 方法是要实现的抽象方法。apply 方法接受一个类型为 T 的参数，并返回一个类型为 R 的结果。 1 2 3 4 @FunctionalInterface public interface Function\u0026lt;T, R\u0026gt; { R apply(T t); } Function接口中的compose、andThen和identity方法使得函数式编程在Java中更加强大和灵活。\nandThen\nandThen方法用于将两个Function实例串联起来，其中第一个函数的输出作为第二个函数的输入。其签名如下：\n1 default \u0026lt;V\u0026gt; Function\u0026lt;T, V\u0026gt; andThen(Function\u0026lt;? super R, ? extends V\u0026gt; after) 示例\n假设我们有两个函数，一个将字符串转换为大写，另一个计算字符串的长度：\n1 2 3 4 5 6 Function\u0026lt;String, String\u0026gt; toUpperCase = String::toUpperCase; Function\u0026lt;String, Integer\u0026gt; stringLength = String::length; Function\u0026lt;String, Integer\u0026gt; upperCaseLength = toUpperCase.andThen(stringLength); int length = upperCaseLength.apply(\u0026#34;hello world\u0026#34;); // 结果是11 compose\ncompose方法与andThen相反，它用于先执行作为参数传入的函数，然后执行调用compose的函数。其签名如下：\n1 default \u0026lt;V\u0026gt; Function\u0026lt;V, R\u0026gt; compose(Function\u0026lt;? super V, ? extends T\u0026gt; before) 示例\n使用上面相同的函数，但这次我们改用compose来实现：\n1 2 3 Function\u0026lt;String, Integer\u0026gt; upperCaseLengthCompose = stringLength.compose(toUpperCase); int lengthCompose = upperCaseLengthCompose.apply(\u0026#34;hello world\u0026#34;); // 结果仍然是11 identity\nidentity方法返回一个不进行任何操作的Function，即直接返回输入参数。这在需要传递一个原样输出的函数时非常有用。其签名如下：\n1 static \u0026lt;T\u0026gt; Function\u0026lt;T, T\u0026gt; identity() 示例\n1 2 3 Function\u0026lt;String, String\u0026gt; identityFunction = Function.identity(); String result = identityFunction.apply(\u0026#34;hello world\u0026#34;); // 结果是\u0026#34;hello world\u0026#34; 方法引用 方法引用的三种类型\n指向静态方法的方法引用 指向任意类型实例方法的方法引用 指向现有对象的实例方法的方法引用 指向静态方法的方法引用\n假设我们有一个静态方法static int findLength(String s)，它返回一个字符串的长度：\n1 2 3 4 5 public class Utils { public static int findLength(String s) { return s.length(); } } 使用Function\u0026lt;T,R\u0026gt;和方法引用：\n1 Function\u0026lt;String, Integer\u0026gt; lengthFunction = Utils::findLength; 指向任意类型实例方法的方法引用\n如果我们想引用String类的length()实例方法：\n1 Function\u0026lt;String, Integer\u0026gt; lengthFunction = String::length; 这里不需要具体的实例，我们直接通过类名引用实例方法。\n指向现有对象的实例方法的方法引用\n如果我们有一个现有的对象，比如List\u0026lt;String\u0026gt;，并想引用它的size方法：\n1 2 List\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;); Supplier\u0026lt;Integer\u0026gt; sizeSupplier = list::size; 这里Supplier\u0026lt;T\u0026gt;是另一个函数式接口，它不接受参数但是返回一个结果。\nStream 流只能消费一次\n流是内部迭代\n流的使用包括三件事\n一个数据源（如集合）来执行一个查询。 一个中间操作链，形成一条流的流水线。 一个终端操作，执行流水线，并生成结果 你可以利用 reduce 方法将流中所有的元素迭代合并成一个结果，例如求和或查找最大 元素。\nfilter和map等操作是无状态的，它们并不存储任何状态。reduce等操作要存储状态才 能计算出一个值。sorted和distinct等操作也要存储状态，因为它们需要把流中的所 有元素缓存起来才能返回一个新的流。这种操作称为有状态操作。\n流有三种基本的原始类型特化：IntStream、DoubleStream 和 LongStream。它们的操 作也有相应的特化。\n流不仅可以从集合创建，也可从值、数组、文件以及iterate与generate等特定方法 创建。\n无限流是没有固定大小的流。\nJava Streams API常用操作 类别 操作 描述 筛选和切片 filter 对流中的元素进行筛选，只保留满足谓词的元素。 distinct 通过流所生成元素的 hashCode() 和 equals() 去除重复元素。 skip 跳过流中的前N个元素。 limit 截断流，使其元素不超过给定数量。 转换 map 对流中的每个元素应用函数，将其转换成其他形式或提取信息。 flatMap 将流中的每个值都换成另一个流，然后把所有流连接起来成为一个流。 查找和匹配 findFirst 返回流中的第一个元素，如果流为空，返回空的Optional。 findAny 返回流中的任意元素，如果流为空，返回空的Optional。 allMatch 检查流中的元素是否都满足给定的谓词。 noneMatch 检查流中的元素是否都不满足给定的谓词。 anyMatch 检查流中是否至少有一个元素满足给定的谓词。 归约 reduce 将流中元素反复结合起来，得到一个值。 有状态操作 sorted 流中元素按自然顺序排序或按给定的比较器排序。 distinct 通过流所生成元素的 hashCode() 和 equals() 去除重复元素。 原始类型流 IntStream, DoubleStream, LongStream 基本类型的流，提供了额外的数值计算相关的方法。 流的创建 从集合、值、数组、文件创建 流可以通过集合的 stream() 方法，Arrays.stream，以及 Files.lines 等方法创建。 iterate 和 generate 用于创建无限流。 summarizingLong、summarizingDouble summarizingLong和summarizingDouble是两个非常有用的收集器（Collectors），它们能够对流中元素的某个长整型或双精度属性进行汇总统计。这些收集器生成的是LongSummaryStatistics或DoubleSummaryStatistics实例，分别用于长整型和双精度值的统计信息，包括元素数量、总和、最小值、最大值以及平均值。\njoining joining是Java中java.util.stream.Collectors类提供的一种工厂方法，用于将流中的元素在遍历过程中合并成一个字符串。这个方法非常适合在处理字符串集合或者需要将对象转换为字符串并连接起来的情况。joining方法有几个重载版本，可以根据需要选择使用。\n1.无参版本\n当不需要在连接的字符串之间添加分隔符、前缀或后缀时，可以使用最简单的形式：\n1 public static Collector\u0026lt;CharSequence, ?, String\u0026gt; joining(CharSequence delimiter) 这将简单地将输入元素连接成一个字符串。\n示例\n1 2 3 List\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;Java\u0026#34;, \u0026#34;Python\u0026#34;, \u0026#34;JavaScript\u0026#34;); String result = list.stream().collect(Collectors.joining()); // 结果: \u0026#34;JavaPythonJavaScript\u0026#34; 2.带有分隔符的版本\n如果想要在每个元素之间添加一个分隔符，可以使用带有一个字符串参数的joining：\n1 public static Collector\u0026lt;CharSequence, ?, String\u0026gt; joining(CharSequence delimiter) 示例\n1 2 3 codeList\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;Java\u0026#34;, \u0026#34;Python\u0026#34;, \u0026#34;JavaScript\u0026#34;); String result = list.stream().collect(Collectors.joining(\u0026#34;, \u0026#34;)); // 结果: \u0026#34;Java, Python, JavaScript\u0026#34; 3.带有分隔符、前缀和后缀的版本\n最完整的joining版本允许在结果字符串的开始和结束添加前缀和后缀，同时在元素之间添加分隔符：\n1 public static Collector\u0026lt;CharSequence, ?, String\u0026gt; joining(CharSequence delimiter, CharSequence prefix, CharSequence suffix) 示例：\n1 2 3 javaCopy codeList\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;Java\u0026#34;, \u0026#34;Python\u0026#34;, \u0026#34;JavaScript\u0026#34;); String result = list.stream().collect(Collectors.joining(\u0026#34;, \u0026#34;, \u0026#34;[\u0026#34;, \u0026#34;]\u0026#34;)); // 结果: \u0026#34;[Java, Python, JavaScript]\u0026#34; 广义的归约汇总 Collectors.reducing 工厂方法是所有这些特殊情况的一般化\n第一个参数是归约操作的起始值\n第二个参数就是转换函数\n第三个参数是累积函数\n1 int totalCalories = menu.stream().collect(reducing(0, Dish::getCalories, (i, j) -\u0026gt; i + j)); groupingBy 1 2 3 4 public static \u0026lt;T, K, A, D\u0026gt; Collector\u0026lt;T, ?, Map\u0026lt;K, D\u0026gt;\u0026gt; groupingBy( Function\u0026lt;? super T, ? extends K\u0026gt; classifier, Collector\u0026lt;? super T, A, D\u0026gt; downstream ) 工作原理\n分类：对流中的每个元素使用分类函数classifier，根据其返回值进行分组。这个返回值决定了元素属于哪个分组键K。 收集：对于每个分组，使用提供的下游收集器downstream对该分组中的元素进行进一步处理，生成结果类型D。 结果映射：最终，方法生成一个映射Map\u0026lt;K, D\u0026gt;，其中每个键K（分组标准）都映射到一个D类型的值（下游收集器的结果）。 Function.identity() 通过返回一个简单的恒等函数，它允许保持元素不变或作为原始形式传递，同时满足函数式接口的需求。\n1 2 3 static \u0026lt;T\u0026gt; Function\u0026lt;T, T\u0026gt; identity() { return t -\u0026gt; t; } parallel(并行流) parallel 流转换成并行流\n1 2 3 4 5 6 public static long parallelSum(long n) { return Stream.iterate(1L, i -\u0026gt; i + 1) // 从1开始生成一个无限流，每次递增1 .limit(n) // 限制流的大小为n .parallel() // 将流转换为并行流 .reduce(0L, Long::sum); // 使用reduce操作进行求和 } 流的数据源和可分解性\n类型 可分解性 ArrayList 较佳 LinkedList 差 IntStream.range 较佳 Stream.iterate 差 HashSet 好 TreeSet 好 高效使用并行流\n通过测量耗时判断是否使用\n留意装箱,自动装箱和拆箱操作会大大降低性能\nlimit 和 findFirst 等依赖于元素顺序的操作，它们在并行流上执行的代价非常大\n对于较小的数据量，选择并行流几乎从来都不是一个好的决定\n考虑终端操作中合并步骤的代价是大是小,如果这一步代价很大，那么组合每个子流产生的部分结果所付出的代价就可能会超出通过并行流得到的性能提升\n分支/合框架 Java 8 引入了分支/合并框架（Fork/Join Framework），这是一个用于并行执行任务的框架，旨在充分利用多核处理器的计算能力。它是一种实现了工作窃取算法（work-stealing algorithm）的框架，允许多个处理器核心更高效地处理大量任务，尤其是那些可以递归分解为更小任务的工作。\n核心概念\nFork：将一个大任务分解成若干个小任务，这些小任务可以并行执行。\u0026ldquo;Fork\u0026quot;是这个过程的术语，意味着\u0026quot;分支\u0026quot;出新的子任务。 Join：等待分支出去的任务完成，并将结果合并起来。\u0026ldquo;Join\u0026quot;指的是将这些并行执行的任务的结果合并到一起，完成整个任务。 关键组件\nForkJoinPool：这是执行ForkJoinTask任务的线程池。它使用工作窃取算法来优化任务的执行，使得所有线程都尽可能保持忙碌状态。 ForkJoinTask:这是要执行的任务的基类。有两个重要的子类： RecursiveAction：用于没有返回结果的任务。 RecursiveTask：用于有返回结果的任务。 工作窃取算法\n工作窃取算法是分支/合并框架的核心。每个处理器都有自己的任务队列。当一个处理器完成了自己队列中的所有任务后，它可以随机选择一个其他处理器，\u0026ldquo;窃取\u0026quot;一部分任务来执行。这种方法提高了线程之间的工作负载均衡，减少了闲置时间\nSpliterator Spliterator是Java 8中引入的一个接口，设计用来进一步提高并行处理能力。它在java.util包中，主要用于遍历和分割数据源，以便于进行并行计算。与Iterator相比，Spliterator提供了更多的功能，特别是对于并行迭代操作而言。\n关键方法\nSpliterator接口定义了几个关键方法：\ntryAdvance(Consumer\u0026lt;? super T\u0026gt; action)：如果剩余元素存在，则对下一个元素执行给定的操作，并返回true；否则返回false。这类似于Iterator的hasNext和next方法的结合体。 forEachRemaining(Consumer\u0026lt;? super T\u0026gt; action)：对剩余每个元素执行给定的操作，直到所有元素都被处理或操作抛出异常。 trySplit()：尝试分割此Spliterator，以便部分元素由当前Spliterator处理，而另一部分元素由新的Spliterator处理。这是并行处理的关键。 estimateSize()：返回此Spliterator中剩余元素的估计数量。 characteristics()：返回此Spliterator的特征值，这是一个位模式，表示该Spliterator的属性集。 2.高效 Java8 编程 Lambda 表达式优化代码 用Lambda表达式取代匿名类 原代码使用匿名类\n1 2 3 4 5 6 codeRunnable runnable = new Runnable() { @Override public void run() { System.out.println(\u0026#34;Running in runnable\u0026#34;); } }; 重构后使用Lambda表达式\n1 Runnable runnable = () -\u0026gt; System.out.println(\u0026#34;Running in runnable\u0026#34;); 用方法引用重构Lambda表达式 原Lambda表达式代码\n1 Consumer\u0026lt;String\u0026gt; printer = s -\u0026gt; System.out.println(s); 重构后使用方法引用\n1 Consumer\u0026lt;String\u0026gt; printer = System.out::println; 用Stream API重构命令式的数据处理 命令式编程风格（原代码）\n1 2 3 4 5 6 codeList\u0026lt;String\u0026gt; filtered = new ArrayList\u0026lt;\u0026gt;(); for(String string : strings) { if(string.startsWith(\u0026#34;J\u0026#34;)) { filtered.add(string); } } 重构后使用Stream API\n1 2 3 javaCopy codeList\u0026lt;String\u0026gt; filtered = strings.stream() .filter(s -\u0026gt; s.startsWith(\u0026#34;J\u0026#34;)) .collect(Collectors.toList()); 使用Lambda表达式改进代码封装性和可读性 如果你发现需要频繁地从客户端代码查询对象状态，仅为了调用该对象的一个方法，可以通过接收Lambda或方法引用作为参数的方式来改进。\n重构前的代码\n1 2 3 javaCopy codeif(logger.isEnabled()) { logger.log(\u0026#34;Message with \u0026#34; + parameter); } 改进后的代码\n定义一个新的日志方法，接受一个Supplier\u0026lt;String\u0026gt;类型的Lambda表达式作为参数，这样可以延迟消息构建的过程，只有在日志器启用的情况下才进行：\n1 2 3 4 5 6 // 在Logger类中添加 public void logWithCondition(Supplier\u0026lt;String\u0026gt; messageSupplier) { if (this.isEnabled()) { log(messageSupplier.get()); } } 然后客户端代码可以这样调用：\n1 2 javaCopy code logger.logWithCondition(() -\u0026gt; \u0026#34;Message with \u0026#34; + parameter); 这样，客户端代码就不需要直接查询日志器的状态了。通过将参数构建（或者说是计算）延迟到确实需要日志消息的时刻，提高了代码的封装性和可读性，同时也避免了在日志器未启用时不必要的字符串拼接操作。\n重构|调试|测试 延迟执行和环绕执行 延迟执行（Lazy Execution） 延迟执行是编程中的一种策略，其中计算或代码执行被推迟到其结果实际需要的那一刻。这种策略在处理大量数据或进行资源密集型操作时特别有用，因为它可以提高应用程序的效率和响应能力。在Java中，延迟执行常常与流（Streams）、延迟加载和懒惰初始化等概念相关联。\n环绕执行（Around Execution） 环绕执行是一种编程模式，通常用于资源管理、监控、日志记录或安全控制等场景。这种模式允许开发者在方法执行前后执行一些预处理和后处理代码，而不需要修改原有方法的代码。在Java中，环绕执行经常通过使用代理（Proxy）、装饰器模式或AOP（面向切面编程）框架如Spring AOP来实现。\nLambda 与 设计模式 策略模式 模版方法 观察者模式 责任链模式 工厂模式 peek peek 是 Stream API 中的一个中间操作，它允许你在不改变流中元素的情况下，对每个元素执行操作，主要用于调试目的，因为它允许查看流中的元素而不会干扰后续的操作。\n1 Stream\u0026lt;T\u0026gt; peek(Consumer\u0026lt;? super T\u0026gt; action) 默认方法 目的: 它让类可以自动地继承接口的一个默认实现,它让类库的设计者放心地改进应用程序接口，无需担忧对遗留代码的影响。\n三种兼容性 二进制级的兼容（Binary Compatibility）\n定义：如果一个应用程序在升级了使用的库或组件之后，不需要重新编译，仍然可以正常运行，那么这个库或组件的新版本就被认为是与旧版本在二进制级别上兼容的。 关键点：这种兼容性确保了编译后的程序代码（二进制代码）在库或组件更新后仍可运行，无需任何修改。这通常涉及到API中函数的签名、数据类型的布局和大小、以及类成员的顺序和可访问性等方面。 源代码级的兼容（Source Compatibility）\n定义：如果在库或组件更新后，应用程序的源代码不需要修改就能重新编译并正常运行，那么这个更新被认为是源代码级别上兼容的。 关键点：这种兼容性强调源代码在经历库或组件的版本升级后仍旧可以不经修改直接编译通过。它关注于API的使用方式，包括函数、类的命名，参数的类型和数量，返回值类型等。 函数行为的兼容（Functional Behavior Compatibility）\n定义：如果库或组件的功能更新后，其公开的函数或方法的行为（包括副作用、执行结果和性能特征）保持不变，那么这个更新被认为保持了函数行为的兼容。 关键点：这种兼容性确保了即使库或组件的内部实现发生变化，对外提供的功能和预期的行为没有改变。对于使用该库或组件的开发者来说，他们可以预期即便更新了依赖，其应用程序的功能表现不会受到影响。 默认方法的使用模式 可选方法 放置一个空的实现，减少无效的模版代码。\n1 2 3 4 5 6 7 interface Iterator\u0026lt;T\u0026gt; { boolean hasNext(); T next(); default void remove() { throw new UnsupportedOperationException(); } } 行为的多继承 默认方法提供了一种多重继承的行为实现机制。类可以从多个接口继承默认方法的实现，解决了之前Java中的多重继承限制。在遇到多个接口定义相同默认方法的情况下，实现类必须覆盖该方法，以解决冲突。\n方法解决冲突 类中的方法优先级最高。类或父类中声明的方法的优先级高于任何声明为默认方法的优先级。 如果无法依据第一条进行判断，那么子接口的优先级更高：函数签名相同时，优先选择拥有最具体实现的默认方法的接口，即如果B继承了A，那么B就比A更加具体。 最后，如果还是无法判断，继承了多个接口的类必须通过显式覆盖和调用期望的方法。 CompletableFuture CompletableFuture 提供了丰富的方法来处理异步编程的需求。以下是一些最常用的方法：\n创建方法 static \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; supplyAsync(Supplier\u0026lt;U\u0026gt; supplier) 异步地执行一个 Supplier 供给型函数。 static \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; supplyAsync(Supplier\u0026lt;U\u0026gt; supplier, Executor executor) 在指定的 Executor 中异步地执行一个 Supplier 函数。 转换和处理结果的方法 \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; thenApply(Function\u0026lt;? super T,? extends U\u0026gt; fn) 当 CompletableFuture 完成时，将结果传递给提供的函数。 \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; thenApplyAsync(Function\u0026lt;? super T,? extends U\u0026gt; fn) 异步地应用一个函数到 CompletableFuture 的结果上。 \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; thenApplyAsync(Function\u0026lt;? super T,? extends U\u0026gt; fn, Executor executor) 在指定的 Executor 中异步地应用一个函数到 CompletableFuture 的结果上。 消费结果的方法 CompletableFuture\u0026lt;Void\u0026gt; thenAccept(Consumer\u0026lt;? super T\u0026gt; action) 当 CompletableFuture 完成时，给定的动作会被执行，消费 CompletableFuture 的结果。 CompletableFuture\u0026lt;Void\u0026gt; thenAcceptAsync(Consumer\u0026lt;? super T\u0026gt; action) 异步地消费 CompletableFuture 的结果。 CompletableFuture\u0026lt;Void\u0026gt; thenAcceptAsync(Consumer\u0026lt;? super T\u0026gt; action, Executor executor) 在指定的 Executor 中异步地消费 CompletableFuture 的结果。 组合 CompletableFuture 的方法 \u0026lt;U,V\u0026gt; CompletableFuture\u0026lt;V\u0026gt; thenCombine(CompletionStage\u0026lt;? extends U\u0026gt; other, BiFunction\u0026lt;? super T,? super U,? extends V\u0026gt; fn) 当两个 CompletionStage 都正常完成时，将它们的结果传递给提供的函数。 \u0026lt;U,V\u0026gt; CompletableFuture\u0026lt;V\u0026gt; thenCombineAsync(CompletionStage\u0026lt;? extends U\u0026gt; other, BiFunction\u0026lt;? super T,? super U,? extends V\u0026gt; fn) 异步地组合两个 CompletionStage 的结果，并应用函数。 \u0026lt;U,V\u0026gt; CompletableFuture\u0026lt;V\u0026gt; thenCombineAsync(CompletionStage\u0026lt;? extends U\u0026gt; other, BiFunction\u0026lt;? super T,? super U,? extends V\u0026gt; fn, Executor executor) 在指定的 Executor 中异步地组合两个 CompletionStage 的结果，并应用函数。 异常处理的方法 CompletableFuture\u0026lt;T\u0026gt; exceptionally(Function\u0026lt;Throwable, ? extends T\u0026gt; fn) 当 CompletableFuture 完成异常时，提供的函数将被调用，可以返回替代的结果。 \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; handle(BiFunction\u0026lt;? super T, Throwable, ? extends U\u0026gt; fn) 当 CompletableFuture 完成时（无论正常还是异常），提供的函数都会被调用，并允许返回结果或抛出异常。 \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; handleAsync(BiFunction\u0026lt;? super T, Throwable, ? extends U\u0026gt; fn) 异步地处理 CompletableFuture 的完成（无论正常还是异常）。 \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; handleAsync(BiFunction\u0026lt;? super T, Throwable, ? extends U\u0026gt; fn, Executor executor) 在指定的 Executor 中异步地处理 CompletableFuture 的完成（无论正常还是异常）。 并行——使用流还是CompletableFutures？\n如果你进行的是计算密集型的操作，并且没有I/O，那么推荐使用Stream接口，因为实现简单，同时效率也可能是最高的（如果所有的线程都是计算密集型的，那就没有必要创建比处理器核数更多的线程）。 反之，如果你并行的工作单元还涉及等待I/O的操作（包括网络连接等待），那么使用CompletableFuture灵活性更好，你可以像前文讨论的那样，依据等待/计算，或者W/C的比率设定需要使用的线程数。这种情况不使用并行流的另一个原因是，处理流的流水线中如果发生I/O等待，流的延迟特性会让我们很难判断到底什么时候触发了等待。**** 新的日期和时间API LocalDate 内容：表示不带时间的日期，例如 2023-03-30。 常用API now()：获取当前日期。 of(year, month, day)：创建一个指定年月日的日期。 plusDays(long daysToAdd)、minusDays(long daysToSubtract)：日期加减操作。 getDayOfWeek()、getMonth()、getYear()：获取日期的各个部分。 LocalTime 内容：表示不带日期的时间，例如 10:15:30。 常用API now()：获取当前时间。 of(hour, minute, second)：创建一个指定时分秒的时间。 plusHours(long hoursToAdd)、minusHours(long hoursToSubtract)：时间加减操作。 getHour()、getMinute()、getSecond()：获取时间的各个部分。 Instant 内容：表示时间线上的一个瞬时点，它是以 Unix 时间戳的形式来存储的。 常用API now()：获取当前的瞬时点。 ofEpochMilli(long epochMilli)：根据 Unix 时间戳创建 Instant 实例。 plusMillis(long millisToAdd)、minusMillis(long millisToSubtract)：瞬时点的加减操作。 Duration 内容：表示两个时刻之间的时间量，以秒和纳秒为单位。 常用API between(Temporal startInclusive, Temporal endExclusive)：计算两个时间点之间的 Duration。 ofDays(long days)、ofHours(long hours)、ofMinutes(long minutes)：创建指定时间长度的 Duration。 plus(Duration duration)、minus(Duration duration)：Duration 的加减操作。 Period 内容：表示两个日期之间的年月日的时间量。 常用API between(LocalDate startDateInclusive, LocalDate endDateExclusive)：计算两个日期之间的 Period。 ofYears(int years)、ofMonths(int months)、ofDays(int days)：创建指定时间长度的 Period。 plus(Period period)、minus(Period period)：Period 的加减操作。 附录 常用的函数式接口 接口名 方法签名 用途 其他方法 Consumer\u0026lt;T\u0026gt; void accept(T t) 接受单个输入参数并且不返回结果的操作（消费者）。 N/A Supplier\u0026lt;T\u0026gt; T get() 无需输入参数，返回一个结果。 N/A Function\u0026lt;T, R\u0026gt; R apply(T t) 接受一个输入参数，返回一个结果。 default \u0026lt;V\u0026gt; Function\u0026lt;V, R\u0026gt; compose(Function\u0026lt;? super V, ? extends T\u0026gt; before)\ndefault \u0026lt;V\u0026gt; Function\u0026lt;T, V\u0026gt; andThen(Function\u0026lt;? super R, ? extends V\u0026gt; after)\nstatic \u0026lt;T\u0026gt; Function\u0026lt;T, T\u0026gt; identity() Predicate\u0026lt;T\u0026gt; boolean test(T t) 确定类型为T的对象是否满足某约束，并返回boolean值。 default Predicate\u0026lt;T\u0026gt; and(Predicate\u0026lt;? super T\u0026gt; other)\ndefault Predicate\u0026lt;T\u0026gt; negate()\ndefault Predicate\u0026lt;T\u0026gt; or(Predicate\u0026lt;? super T\u0026gt; other) BiConsumer\u0026lt;T,U\u0026gt; void accept(T t, U u) 接受两个输入参数的操作，并且不返回任何结果。 N/A BiFunction\u0026lt;T,U,R\u0026gt; R apply(T t, U u) 接受两个输入参数的函数，并且返回一个结果。 N/A UnaryOperator\u0026lt;T\u0026gt; 继承自Function 一种特殊的Function，输入参数类型和返回类型相同。 static \u0026lt;T\u0026gt; UnaryOperator\u0026lt;T\u0026gt; identity() BinaryOperator\u0026lt;T\u0026gt; 继承自BiFunction 一种特殊的BiFunction，两个输入参数和返回类型相同。 N/A Optional 类主要方法 方法名 描述 empty() 创建一个空的 Optional 实例。 of(T value) 创建一个包含非空值的 Optional 实例。如果 value 为 null，则抛出 NullPointerException。 ofNullable(T value) 创建一个 Optional 实例，如果指定的值为 null，则返回一个空的 Optional。 isPresent() 如果值存在且非空，则返回 true；否则返回 false。 isEmpty() Java 11 中引入，如果值不存在或为空，则返回 true；否则返回 false。 get() 如果值存在，则返回该值；否则抛出 NoSuchElementException。 ifPresent(Consumer\u0026lt;? super T\u0026gt; action) 如果值存在，执行给定的操作。 ifPresentOrElse(Consumer\u0026lt;? super T\u0026gt; action, Runnable emptyAction) Java 9 中引入，如果值存在，执行给定的操作；否则执行另一个操作。 orElse(T other) 如果有值则返回该值，否则返回一个默认值。 orElseGet(Supplier\u0026lt;? extends T\u0026gt; other) 如果有值则返回该值，否则返回一个由 Supplier 接口生成的值。 orElseThrow() 如果有值则返回该值，否则抛出 NoSuchElementException。 orElseThrow(Supplier\u0026lt;? extends X\u0026gt; exceptionSupplier) 如果有值则返回该值，否则抛出由提供的 Supplier 接口生成的异常。 filter(Predicate\u0026lt;? super T\u0026gt; predicate) 如果有值且满足给定的条件，则返回包含该值的 Optional；否则返回一个空的 Optional。 map(Function\u0026lt;? super T,? extends U\u0026gt; mapper) 如果有值，则对该值执行给定的映射函数，并返回一个 Optional 类型的结果。 flatMap(Function\u0026lt;? super T, ? extends Optional\u0026lt;? extends U\u0026gt;\u0026gt; mapper) 如果有值，则将提供的 Optional 映射函数应用于该值，否则返回一个空的 Optional。 stream() Java 9 中引入，如果有值则返回仅包含该值的顺序 Stream，否则返回一个空的 Stream。 PECS原则 一个好的经验法则是所谓的PECS原则（\u0026ldquo;Producer Extends, Consumer Super\u0026rdquo;），由Joshua Bloch提出：\n如果你需要一个提供者（Producer），即希望从泛型数据类型中读取数据，使用extends。 如果你需要一个消费者（Consumer），即希望写入数据到泛型数据类型中，使用super。 ","date":"2024-03-07T00:07:56+08:00","image":"/hiwikhome/note/java8/post_huf7c4e2b6598e86764dcd35b54fe8e951_967916_120x120_fill_box_smart1_3.png","permalink":"/hiwikhome/note/java8/","title":"《Java8实战》笔记"},{"content":"Windows 常用软件 🔍 文件管理与查看 Bandizip：不仅支持ZIP、7Z、RAR等常见格式，Bandizip还提供了分卷压缩、自解压功能和多核心压缩技术，使其在文件压缩与解压缩时更加高效。更多信息 SumatraPDF：以极简主义设计著称，SumatraPDF不仅轻巧快速，还支持PDF、ePub、MOBI、XPS、DjVu、CHM、CBZ和CBR文件格式，非常适合日常文档阅读需求。更多信息 wiztree: 一款强大的磁盘空间分析工具，主要用于Windows操作系统。它能快速扫描你的硬盘驱动器，并以树状图的形式显示哪些文件和文件夹占用了最多的磁盘空间。这对于清理硬盘空间、管理文件和识别大型无用文件非常有帮助。更多信息 🧑‍💻 编程与开发 Git：是开发者协作和源代码管理的标准工具，它的分布式架构让项目版本控制更灵活、更可靠。更多信息 Python 3.10：引入了模式匹配、改进的类型注解等新特性，进一步增强了这门语言的表达力和代码的可读性。更多信息 PyCharm：提供智能代码编辑、调试、测试、版本控制集成等功能，非常适合Python开发者。更多信息 IntelliJ IDEA：专为Java开发者设计，提供深度代码分析、智能代码补全和一系列现代化工具，极大地提升开发效率。更多信息 Visual Studio Code：一个轻量级但功能强大的源代码编辑器，支持几乎所有主流的编程语言，通过海量的扩展库可定制开发环境。更多信息 🌐 网络工具 Clash for Windows：提供复杂的网络代理规则配置，支持SS、SSR、Vmess等多种代理协议，适合需要精细网络代理设置的高级用户。GitHub地址 📑 笔记与文档 Notion：集成笔记、知识库、项目管理等功能于一体，支持丰富的自定义和协作功能，适合个人和团队组织信息和任务。更多信息 Typora：提供干净的写作界面和即时渲染Markdown文档的能力，支持图片、表格、数学公式等Markdown扩展，适合需要高效写作和笔记的用户。更多信息 📐 效率工具 Everything：提供即时文件搜索能力，通过建立文件索引实现秒级搜索响应，极大地提升了文件检索效率。更多信息 UTools：通过插件扩展实现多种效率工具的集成，包括快速启动程序、搜索文件、临时笔记等，适合追求效率的现代工作者。更多信息 持续更新中\u0026hellip;..\n","date":"2024-03-03T15:10:33+08:00","image":"/hiwikhome/software/post_hu8d8bd786c26d9b7a8c17db90f956bd2b_860720_120x120_fill_box_smart1_3.png","permalink":"/hiwikhome/software/","title":"Windows 常用软件"},{"content":"🎨 前置准备 在开始部署之前，确保你的系统已经安装了以下必要的软件和工具：\nGit - 用于克隆stable-diffusion-webui的仓库。可以从Git官方下载页面下载适合你操作系统的版本。 Python 3.10.6 - stable-diffusion-webui的运行需要依赖Python。请从Python官网下载并安装Python 3.10.6版本，安装时勾选Add to PATH选项。 CUDA - 使用GPU加速，需要安装NVIDIA的CUDA工具包。具体版本和安装步骤请参考NVIDIA官方文档。 🔌 部署步骤 打开命令提示符（或终端），使用git命令克隆stable-diffusion-webui项目 1 git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui clone 完成后，进入项目目录，运行webui-user.bat文件启动webui 启动成功 💽 切换镜像源 为了加快Python包的下载速度，可以切换到国内的镜像源： 1 pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple 如果你在连接时遇到网络问题，可以考虑设置网络代理 🅰 安装汉化语言包 stable-diffusion-webui支持通过扩展来安装汉化语言包，以下是具体的操作步骤：\n启动stable-diffusion-webui后，进入\u0026quot;Extensions\u0026quot;选项卡。 点击\u0026quot;Install from URL\u0026quot;，在\u0026quot;URL for extension\u0026rsquo;s git repository\u0026quot;输入框中，粘贴或输入汉化包的Git仓库地址https://github.com/VinsonLaro/stable-diffusion-webui-chinese。 点击下方的黄色\u0026quot;Install\u0026quot;按钮完成安装，随后需要重启WebUI。点击\u0026quot;Installed\u0026quot;选项，然后点击\u0026quot;Apply and restart UI\u0026quot;，最后点击网页下方的\u0026quot;Reload UI\u0026quot;完成重启。 进入\u0026quot;Settings\u0026quot;，在左侧找到\u0026quot;User interface\u0026quot;选项，在页面最下方找到\u0026quot;Localization (requires restart)\u0026quot;，选择\u0026quot;Chinese-All\u0026quot;或者\u0026quot;Chinese-English\u0026quot;。 点击页面最上方的黄色\u0026quot;Apply settings\u0026quot;按钮，然后点击右侧的\u0026quot;Reload UI\u0026quot;完成汉化。 ","date":"2024-03-03T10:05:05+08:00","image":"/hiwikhome/stable-diffusion-webui/post_hu04e5ae8a7316ec5cb02fc4b33df8089e_1251226_120x120_fill_box_smart1_3.png","permalink":"/hiwikhome/stable-diffusion-webui/","title":"stable-diffusion-webui 本地部署"},{"content":"🍤 Hugo文章创建 在Hugo中创建文章时，你可以在文章的前言（Front Matter）中定义多种属性，以控制文章的各种设置和行为。Front Matter是位于Markdown文件顶部的区域，用于存储元数据，如标题、日期、描述等。Hugo 支持 YAML、TOML 和 JSON 格式的 Front Matter。下面是一些常见属性及其说明：\n基本属性 title: 文章的标题。 date: 文章的发布日期，通常用于控制文章的排序。 draft: 布尔值，指示文章是否是草稿。如果为true，则文章在构建生产版本的站点时不会被发布。 author: 文章的作者名字。 description: 文章的简短描述，有时用于搜索引擎优化（SEO）。 分类和标签 categories: 一个列表，用于指定文章所属的分类。 tags: 一个列表，用于指定文章的标签。 URL和永久链接 slug: 文章的短链接，用于自定义文章的URL。 url: 可以完全自定义文章的URL。 高级设置 weight: 用于手动控制文章在列表中的排序。 aliases: 一个列表，用于为文章指定额外的路径，常用于重定向旧URL到新位置。 series: 用于将文章分组为系列。 图片和资源 images: 一个列表，指定文章的特色图像或相关图像。 resources: 用于管理文章附件和资源，如图片、PDF文件等。 🍧Hugo命令 Hugo 是一个快速的静态网站生成器，提供了一系列命令来帮助你创建和管理你的网站。对于本地开发，特别是想避免频繁重新编译的场景，Hugo 提供了实时重载功能，可以在你进行更改时自动重新生成网站，而无需手动重新编译。以下是一些Hugo的常用命令以及如何利用 Hugo 的实时重载功能。\nHugo常用命令 hugo：在默认情况下，运行hugo命令会生成整个网站。生成的文件会放在public目录下。 hugo server：启动一个带有实时重载功能的本地服务器。当你修改项目文件时，Hugo 会自动检测这些更改并立即重新生成静态文件，同时刷新浏览器，让你实时看到更改效果。 hugo new site [SITE_NAME]：创建一个新的Hugo网站。这会在指定的[SITE_NAME]目录下创建一个新的Hugo项目结构。 hugo new [PATH]：基于你的主题中定义的架构，创建一个新的内容文件。例如，hugo new posts/my-first-post.md会创建一个新的文章。 hugo check：运行一系列检查，以确保网站配置没有问题。 hugo version：显示当前安装的Hugo版本! 利用Hugo的实时重载功能 运行hugo server命令是开发 Hugo 网站时避免频繁重新编译的最佳实践。这个命令不仅启动了一个本地服务器，还开启了文件更改监听器，自动重新生成网站并推送更新到浏览器。\n1 hugo server 1 hugo server --bind=\u0026#34;0.0.0.0\u0026#34; --baseURL=\u0026#34;http://example.com\u0026#34; 这样，你就可以通过其他设备在同一网络中访问你的本地服务器了。\n其他有用的参数 --buildDrafts或-D：包括草稿内容在内的服务器运行。 --buildFuture：允许显示将来日期的内容。 --disableFastRender：禁用快速渲染模式，每次更改都会完全重建站点，适用于调试。 清除public 这个命令在构建网站之前会自动清理 public 目录。这意味着所有旧文件都会被删除，只有新生成的文件会被放置在 public 文件夹中。使用这个命令可以确保public目录保持最新状态\nhugo --cleanDestinationDir 通过这些命令和参数的使用，你可以高效地管理Hugo项目，并享受快速反馈的开发体验。\n🍰 Hugo 配置类 content content md文件命名用 index.md ,这样放在对应文件夹下的img才能被解析\ncategory 新增 category 时,文件夹名称与 post 中的 categories 属性应保持一致\n","date":"2024-02-27T21:54:28+08:00","image":"/hiwikhome/hugoguide/post_hu5ed620c5e0a4be7cbac7cbb3f279eaa9_3306350_120x120_fill_box_smart1_3.png","permalink":"/hiwikhome/hugoguide/","title":"Hugo 使用指南"}]